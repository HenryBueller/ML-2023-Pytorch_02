{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "421cad5b-58d0-40c2-ae9f-b362a5894cb5",
   "metadata": {},
   "source": [
    "# 00-01_The_Machine_Learning_Landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eadfb4-6039-4eb8-bb71-f3b31a8bf2fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0 Preface\n",
    "\n",
    "基本框架 https://scikit-learn.org/  https://tensorflow.org/  https://keras.io/  \n",
    "python https://learnpython.org   https://docs.python.org/3/tutorial  \n",
    "前置学习 https://homl.info/tutorials.  https://numpy.org/  https://pandas.pydata.org/  https://matplotlib.org/  \n",
    "线上数学 https://khanacademy.org/  \n",
    "其他资源  \n",
    "$\\qquad$机器学习 https://homl.info/ngcourse  \n",
    "$\\qquad$Scikit-Learn’s exceptional User Guide https://homl.info/skdoc  \n",
    "$\\qquad$interactive tutorials https://dataquest.io/  \n",
    "$\\qquad$ML blogs https://homl.info/1  \n",
    "机器学习竞赛 https://kaggle.com/  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0cd6ab-3d5a-4d6f-8597-98b1eaf5e07d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1  The Machine Learning Landscape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c5c71e-deaa-4995-8bc9-3eebc55c1642",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 用处"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef0d8d4-a5ca-4c32-a662-035c3a352611",
   "metadata": {},
   "source": [
    "• Problems for which existing solutions **require a lot of fine-tuning or long lists of rules** (a machine learning model can often simplify code and perform better than the traditional approach)  \n",
    "• **Complex problems** for which using a traditional approach yields no good solution (the best machine learning techniques can perhaps find a solution)  \n",
    "• **Fluctuating environments** (a machine learning system can easily be retrained on new data, always keeping it up to date)  \n",
    "• **Getting insights** about complex problems and large amounts of data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5447fd-012a-43d1-8d13-4db01b89968e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdd0a3c-5f48-4f6b-807d-ffc3daa85af3",
   "metadata": {},
   "source": [
    "• How they are **supervised** during training (supervised, unsupervised, semi-supervised, self-supervised, and others)  \n",
    "• Whether or not they can **learn incrementally on the fly** (online versus batch learning)  \n",
    "• Whether they work by simply **comparing new data points** to known data points, or instead by **detecting patterns** in the training data and building a predictive model, much like scientists do (instance-based versus model-based learning)  \n",
    "\n",
    "监督学习：分类、回归（一些分类方法能用于回归，反之亦然）  \n",
    "半监督学习：二者结合，一些标记、一些没标记  \n",
    "非监督学习：聚类、可视化（比如特征提取降维）、异常检测、Association Rule Learning Algorithms关联规则学习算法  \n",
    "【通常先用降维算法减少数据维度，再用其他学习方法】  \n",
    "自监督学习：全没标记（还原遮盖处、擦除不想要的地方），通常还原模型训练出来后微调成预测识别transfer learning  \n",
    "强化学习：通过给予agent奖励or惩罚，使其学习应对策略  \n",
    "\n",
    "batch learning：offline learning，由于模型不会持续更新，导致发生model rot or data drift，需要用旧数据+新数据从头练出新版本系统（**数据过大用MapReduce+多服务器，或者online learning**）  \n",
    "online learning：增量化训练，训练时能切分数据，训练之后能实时增加新数据，需要检测并及时处理垃圾、异常数据  \n",
    "$\\qquad$<img src=\"handson-ml3-note.assets/image-20230302190733487.png\" alt=\"image-20230302190733487\" style=\"zoom: 75%;\" />  \n",
    "$\\qquad$<img src=\"handson-ml3-note.assets/image-20230302190802007.png\"  style=\"zoom: 80%;\"/>  \n",
    "$\\qquad$learning rate：适应新数据速度（快-忘记旧数据也快，慢-对新数据噪声/outliers不敏感）  \n",
    "$\\qquad$Out-of-core learning（数据多到主存存不下，需要切分） is usually done offline (i.e., not on the live system), so online learning can be a confusing name. Think of it as incremental learning  \n",
    "\n",
    "基于实例学习：背诵式学习。记住数据，然后用与已知数据（子集）的相似度作为新实例泛化标准  \n",
    "基于模型学习：从数据中泛化出模型  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dc1d74-52a6-422f-a608-3c6f66dc405d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 挑战"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d0d403-d354-4d6b-8247-07a75d209b37",
   "metadata": {},
   "source": [
    "坏数据  \n",
    "• 训练数据不足  \n",
    "• 训练数据不具代表性（样本偏好）  \n",
    "• 低质量数据  \n",
    "• 不相关特征（feature engineering：特征选择、特征提取、收集新数据创造新特征）  \n",
    "\n",
    "坏算法  \n",
    "• 过拟合overfit（解决：收集更多数据、减少噪声、通过选择更少参数的模型/减少训练数据属性/限制模型来简化模型）  \n",
    "$\\qquad$regularization：通过限制模型避免过拟合 ，通过超参数hyperparameter控制  \n",
    "$\\qquad$hyperparameter：学习算法而非模型的参数，越大限制越大  \n",
    "• 欠拟合underfit（解决：选择具有更多参数的更强模型、通过feature engineering给算法提供更好的特征、减少模型限制） "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b53728-fa6c-4d65-8692-e146434620df",
   "metadata": {},
   "source": [
    "### 测试和验证"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddc2d22-23fc-4521-af7d-572b452634d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "训练集、测试集、错误率generalization error (or out-of-sample error)  \n",
    "$\\qquad$一般80%训练20%测试，千万级留1%即可\n",
    "\n",
    "超参数调整和模型选择Hyperparameter Tuning and Model Selection   \n",
    "$\\qquad$holdout validation：留出部分训练集the validation set (or the development set, or dev set)以评估各种候选模型  \n",
    "$\\qquad$$\\qquad$太小则模型评估不准，太大则模型在完整训练时可能偏差太大（短跑冠军参加马拉松）  \n",
    "$\\qquad$$\\qquad$解决：perform repeated cross-validation, using many small validation sets\n",
    "        （Each model is evaluated once per validation set after it is trained on the rest of the data. 缺陷：验证集参与训练次数更多）  \n",
    "$\\qquad$$\\qquad$<img src=\"handson-ml3-note.assets/image-20230302173641960.png\" alt=\"image-20230302173641960\" style=\"zoom: 80%;\" />  \n",
    "\n",
    "Data Mismatch  \n",
    "$\\qquad$数据很多，但在投入使用时有代表性的不多  \n",
    "$\\qquad$train-dev表现不好：过拟合。解决：简化模型、获取更多训练数据、清理训练数据  \n",
    "$\\qquad$train-dev表现好：在dev上评估模型  \n",
    "$\\qquad$dev表现不好：data mismatch。解决：预处理来自网络的图片使其更像在手机app会获取的+重新训练  \n",
    "$\\qquad$test：了解在实际使用时可能的表现优劣  \n",
    "$\\qquad$<img src=\"handson-ml3-note.assets/image-20230302175054142.png\" alt=\"image-20230302175054142\" style=\"zoom:80%;\" />  \n",
    "\n",
    "没有免费的午餐原则No Free Lunch Theorem  \n",
    "$\\qquad$模型是数据的简化，因此选择模型就暗含对数据的假定assumptions（线性模型假定数据基本线性，线外点只是噪声）  \n",
    "$\\qquad$NFL原则：不对数据假定就没理由偏好某一模型（因此没有模型先天一定更好）  \n",
    "$\\qquad$实践中，要对数据做出合理假定，评估有限个合理模型而非全部模型  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b24640-e1e6-41f3-97b0-2cabc691c14b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_py3.8",
   "language": "python",
   "name": "pt_py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
